{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import imageio\n",
    "import skimage\n",
    "import scipy # \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import smtplib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(img):\n",
    "    K = 5\n",
    "    rows = img.shape[1]\n",
    "    cols = img.shape[0]\n",
    "    n = img.shape[0] * img.shape[1]\n",
    "    data = img.reshape(-1,3)\n",
    "    data = np.float32(data)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    center,labels,colors = cv2.kmeans(data, K, None, criteria,  10, cv2.KMEANS_PP_CENTERS)\n",
    "\n",
    "    for i in range(0,n):\n",
    "        data[i][0] = colors[labels[i], 0]\n",
    "        data[i][1] = colors[labels[i], 1]\n",
    "        data[i][2] = colors[labels[i], 2]\n",
    "\n",
    "    reduced = data.reshape(cols, rows, 3)\n",
    "    reduced = np.uint8(reduced)\n",
    "\n",
    "    return reduced\n",
    "\n",
    "def getClrs(img):\n",
    "    reduced = kmeans(img)\n",
    "    data = reduced.reshape(-1,3)\n",
    "    diff_clrs = []\n",
    "    init = 0\n",
    "    for color in data:\n",
    "        if init == 0:\n",
    "            diff_clrs = np.asarray([color])\n",
    "            init = 1\n",
    "        else:\n",
    "            if color not in diff_clrs:\n",
    "                diff_clrs = np.concatenate((diff_clrs, np.asarray([color])), axis = 0)\n",
    "\n",
    "    return diff_clrs\n",
    "\n",
    "def checkClrs(clrs):\n",
    "    height = 64\n",
    "    width = 32\n",
    "    init = 0\n",
    "    for color in clrs:\n",
    "        for i in range(width):\n",
    "            if init == 0:\n",
    "                data = np.array([color])\n",
    "                init = 1\n",
    "            else:\n",
    "                data = np.concatenate((data,np.array([color])), axis = 0)\n",
    "\n",
    "    data = data.reshape(1,len(data),3)\n",
    "    data2 = data\n",
    "    for i in range(height):\n",
    "        data = np.concatenate((data,data2), axis = 0)\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
    "        \n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs_A = []\n",
    "        imgs_B = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "            _w = int(w/2)\n",
    "            img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n",
    "\n",
    "            img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "            img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "\n",
    "            # If training => do random flip\n",
    "            if not is_testing and np.random.random() < 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "\n",
    "        imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "        return imgs_A, imgs_B\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path = glob('%s/%s/*' % (self.dataset_name, data_type))\n",
    "\n",
    "        self.n_batches = int(len(path) / batch_size)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch = path[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img in batch:\n",
    "                img = self.imread(img)\n",
    "                h, w, _ = img.shape\n",
    "                half_w = int(w/2)\n",
    "                img_A = img[:, :half_w, :]\n",
    "                img_B = img[:, half_w:, :]\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "\n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path).astype(np.float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amm65\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "D:\\Users\\amm65\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:54: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "[0.96862745 0.82352941 0.71372549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amm65\\.conda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228 175 152]\n",
      " [135 105 120]\n",
      " [ 12  12  33]\n",
      " [ 57  86 150]\n",
      " [ 30  40  95]]\n",
      "press something bro\n",
      "(128, 128, 3)\n",
      "[0.21960784 0.10196078 0.07058824]\n",
      "[[ 68  56  60]\n",
      " [234 145  39]\n",
      " [183 185 141]\n",
      " [ 53 137 172]]\n",
      "press something bro\n",
      "(128, 128, 3)\n",
      "[0.82352941 0.8        0.82352941]\n",
      "[[190 184 187]\n",
      " [105  99 101]\n",
      " [ 47  41  43]\n",
      " [  5   0   2]\n",
      " [241 240 243]]\n",
      "press something bro\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \"\"\"\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ddbf634fb7f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"press something bro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mdataLoaderTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ddbf634fb7f7>\u001b[0m in \u001b[0;36mdataLoaderTest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./images2/%s/%d_%d.png\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"press something bro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mdataLoaderTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         )\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def dataLoaderTest():\n",
    "# Input shape\n",
    "    img_rows = 128\n",
    "    img_cols = 128\n",
    "    channels = 3\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "    # Configure data loader\n",
    "    dataset_name = 'dataset2'\n",
    "    data_loader = DataLoader(dataset_name=dataset_name,\n",
    "                                    img_res=(img_rows, img_cols))\n",
    "    \n",
    "    os.makedirs('./images2/%s' % dataset_name, exist_ok=True)\n",
    "    \n",
    "    batch_size = 1\n",
    "    for batch_i, (real_clrs, imgs) in enumerate(data_loader.load_batch(batch_size)):\n",
    "        img = 0.5 * real_clrs[0] + 0.5\n",
    "        print(img.shape)\n",
    "        print(img[0][0])\n",
    "        clrs = getClrs(img*256)\n",
    "        print(clrs)\n",
    "        check = checkClrs(clrs)\n",
    "        r, c = 1,1\n",
    "        titles = ['Condition']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        axs.imshow(check)\n",
    "        axs.set_title(check)\n",
    "        axs.axis('off')\n",
    "        fig.savefig(\"./images2/%s/%d_%d.png\" % (dataset_name, 1, batch_i))\n",
    "        plt.close()\n",
    "        input(\"press something bro\")\n",
    "        \n",
    "dataLoaderTest()\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClrPipe():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "         # Configure data loader\n",
    "        self.dataset_name = 'dataset2'\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        \n",
    "         # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = tf.keras.layers.Input(shape=self.img_shape)\n",
    "        img_B = tf.keras.layers.Input(shape=self.img_shape)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.generator.compile(loss=['mse'], loss_weights=[15], optimizer=optimizer)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = tf.keras.layers.Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = tf.keras.layers.BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "        \n",
    "        # Image input\n",
    "        d0 = tf.keras.layers.Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "       \n",
    "        #Channel Pool\n",
    "        out1 = conv2d(d7,self.gf*4)\n",
    "        print(out1.shape)\n",
    "        out2 = conv2d(out1,self.gf*2)\n",
    "        print(out2.shape)\n",
    "        out3 = conv2d(out2,self.gf)\n",
    "        print(out3.shape)\n",
    "        out4 = conv2d(out3, 32)\n",
    "        print(out4.shape)\n",
    "        out5 = conv2d(out4, 15)\n",
    "        print(out5.shape)\n",
    "        \n",
    "        #output_img = tf.keras.layers.Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "        return tf.keras.models.Model(d0, out5)\n",
    "    \n",
    "    def trainTest(self, batch_size=1):\n",
    "        for batch_i, (real_clrs, imgs) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "            fake_clrs = self.generator.predict(imgs)\n",
    "            prediction = 0.5 * fake_clrs[0][0][0] + 0.5\n",
    "            print(prediction.shape)\n",
    "            normalized_prediction = prediction.reshape(-1,3)\n",
    "            print(normalized_prediction.shape)\n",
    "            print(normalized_prediction)\n",
    "            colors = checkClrs(normalized_prediction)\n",
    "            print(colors.shape)\n",
    "            r, c = 1, 1\n",
    "            titles = ['Condition']\n",
    "            fig, axs = plt.subplots(r, c)\n",
    "            axs.imshow(colors)\n",
    "            axs.set_title('hi')\n",
    "            axs.axis('off')\n",
    "            fig.savefig(\"./images2/%s/%d_%d.png\" % ('dataset2', 1, batch_i))\n",
    "            plt.close()\n",
    "            input(\"write something bro\")\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (real_clrs, imgs) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # Condition on image input and generate fake color palettes\n",
    "                fake_clrs = self.generator.predict(imgs)\n",
    "                \n",
    "                real_clrs = getClrs(imgs)\n",
    "                print(real_clrs.shape)\n",
    "                \n",
    "                g_loss = self.generator.train_on_batch(fake_clrs, real_clrs)\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        batch_i, self.data_loader.n_batches,\n",
    "                                                                        g_loss[0]/batch_size,\n",
    "                                                                        elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('./images/%s' % self.dataset_name, exist_ok=True)\n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, imgs_B = self.data_loader.load_data(batch_size=3, is_testing=True)\n",
    "        fake_A = self.generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Condition', 'Generated', 'Original']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"./images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 1, 256)\n",
      "(?, 1, 1, 128)\n",
      "(?, 1, 1, 64)\n",
      "(?, 1, 1, 32)\n",
      "(?, 1, 1, 15)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 64, 64, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_316 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 32, 32, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_317 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_288 ( (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_319 (Conv2D)          (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_318 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_289 ( (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 8, 8, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_319 (LeakyReLU)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_290 ( (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_321 (Conv2D)          (None, 4, 4, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_320 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_291 ( (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_322 (Conv2D)          (None, 2, 2, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_321 (LeakyReLU)  (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_292 ( (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 1, 1, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_322 (LeakyReLU)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_293 ( (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_324 (Conv2D)          (None, 1, 1, 256)         2097408   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_323 (LeakyReLU)  (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_294 ( (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_325 (Conv2D)          (None, 1, 1, 128)         524416    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_324 (LeakyReLU)  (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_295 ( (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 1, 1, 64)          131136    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_325 (LeakyReLU)  (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_296 ( (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 1, 1, 32)          32800     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_326 (LeakyReLU)  (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_297 ( (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_328 (Conv2D)          (None, 1, 1, 15)          7695      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_327 (LeakyReLU)  (None, 1, 1, 15)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_298 ( (None, 1, 1, 15)          60        \n",
      "=================================================================\n",
      "Total params: 18,146,155\n",
      "Trainable params: 18,140,301\n",
      "Non-trainable params: 5,854\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = ClrPipe()\n",
    "net.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amm65\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "D:\\Users\\amm65\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:54: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "(5, 3)\n",
      "[[0.50000006 0.49999997 0.4999998 ]\n",
      " [0.5000004  0.50000095 0.50000083]\n",
      " [0.5        0.5000004  0.5000015 ]\n",
      " [0.50000083 0.49999997 0.50000083]\n",
      " [0.49999994 0.4999999  0.5000011 ]]\n",
      "(65, 160, 3)\n",
      "write something bro\n",
      "(15,)\n",
      "(5, 3)\n",
      "[[0.5000011  0.49999997 0.49999994]\n",
      " [0.50000024 0.5000008  0.5       ]\n",
      " [0.5        0.5000005  0.5000012 ]\n",
      " [0.50000066 0.49999994 0.5000003 ]\n",
      " [0.49999994 0.4999999  0.5000002 ]]\n",
      "(65, 160, 3)\n",
      "write something bro\n",
      "(15,)\n",
      "(5, 3)\n",
      "[[0.50000054 0.50000095 0.4999999 ]\n",
      " [0.50000054 0.50000054 0.49999994]\n",
      " [0.49999994 0.5000004  0.5000013 ]\n",
      " [0.50000167 0.5        0.5000014 ]\n",
      " [0.50000006 0.4999998  0.50000083]]\n",
      "(65, 160, 3)\n",
      "write something bro\n",
      "(15,)\n",
      "(5, 3)\n",
      "[[0.5000008  0.50000066 0.49999985]\n",
      " [0.5000001  0.5000005  0.50000006]\n",
      " [0.49999997 0.50000036 0.5000017 ]\n",
      " [0.50000155 0.49999997 0.5000012 ]\n",
      " [0.49999994 0.49999988 0.5000003 ]]\n",
      "(65, 160, 3)\n",
      "write something bro\n",
      "(15,)\n",
      "(5, 3)\n",
      "[[0.5000013  0.5000011  0.5       ]\n",
      " [0.50000024 0.50000024 0.49999994]\n",
      " [0.5        0.5000003  0.5000013 ]\n",
      " [0.5000014  0.49999988 0.5000009 ]\n",
      " [0.49999994 0.4999999  0.49999997]]\n",
      "(65, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "net.trainTest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpecGan",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
